{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac9155b9f5e04400957a6f8bb3f6610c",
        "deepnote_cell_type": "markdown",
        "id": "2v2D1coL7I8i"
      },
      "source": [
        "<h1><center>Laboratorio 6: La solicitud de Sergio ü§ó</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d3d6f6d405c54dbe985a5f4b3e4f9120",
        "deepnote_cell_type": "markdown",
        "id": "YxdTmIPD7L_x"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "851a7788e8214942863cbd4099064ab2",
        "deepnote_cell_type": "markdown",
        "id": "Y2Gyrj-x7N2L"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Tom√°s Ignacio Reyes Oyarz√∫n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f23a189afdec4e198683308db70e43b7",
        "deepnote_cell_type": "markdown",
        "id": "jQ9skYc57Pxi"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Repositorio - TR](https://github.com/TomiReyes/MDS7202-TR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5318f41cda64d4290a7a548956ed725",
        "deepnote_cell_type": "markdown",
        "id": "1M4PoEWm7S80"
      },
      "source": [
        "## Temas a tratar\n",
        "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
        "- Aplicar Pipelines y Column Transformers.\n",
        "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
        "- Familiarizarse con plotly.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "858df483d9e64780a21674afed1d34b8",
        "deepnote_cell_type": "markdown",
        "id": "SuMbiyQZG2Cc"
      },
      "source": [
        "## Descripci√≥n del laboratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "403ffe48ec994afda4b91e670a08d0ef",
        "deepnote_cell_type": "markdown",
        "id": "QZsNO4rUrqCz"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/5a/a6/af/5aa6afde8490da403a21601adf7a7240.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0303baa17d4546feae8c9b88c58470bf",
        "deepnote_cell_type": "markdown",
        "id": "2o0MPuk8rqCz"
      },
      "source": [
        "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
        "\n",
        "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
        "\n",
        "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e78cb41b144041af98928ab26dcfdaa9",
        "deepnote_cell_type": "markdown",
        "id": "hs4KKWF1Hdpo"
      },
      "source": [
        "## Importamos librerias utiles üò∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "95a5533cfd6d49cfb9afc111c44d224f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 15,
        "execution_start": 1714107106552,
        "id": "a4YpMafirqC0",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import plotly.subplots as sp\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "import time\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import plotly.figure_factory as ff\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import IsolationForest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "acbeab32db6146678e75448dddf43da8",
        "deepnote_cell_type": "markdown",
        "id": "UQOXod4gHhSq"
      },
      "source": [
        "## 1. Estudio de Performance üìà [10 Puntos]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "704b56b978254ad3ae12cdbf58f4832d",
        "deepnote_cell_type": "markdown",
        "id": "Gn5u5ICkrqC2"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://user-images.githubusercontent.com/57133330/188281408-c67df9ee-fd1f-4b37-833b-f02848f1ce02.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d35fbdcc5ef045d6a2822622f0714179",
        "deepnote_cell_type": "markdown",
        "id": "y4Z0jTjtrqC2"
      },
      "source": [
        "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
        "\n",
        "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
        "\n",
        "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=800 />\n",
        "\n",
        "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "37580aab6cef4238a8ce42c50a6d35de",
        "deepnote_cell_type": "markdown",
        "id": "maCUNAvZrqC2"
      },
      "source": [
        "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
        "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
        "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 10000. [2 puntos]\n",
        "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en `n_samples`. [4 puntos]\n",
        "\n",
        "\n",
        "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
        "\n",
        "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cell_id": "7f7c25e366754595b13fc2e8116f65a0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 78,
        "execution_start": 1714107108441,
        "id": "i0IZPGPOrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
        "‚ùóNo realice cambios a esta celda a excepci√≥n de n_samples‚ùó\n",
        "\"\"\"\n",
        "\n",
        "# Datos a utilizar\n",
        "\n",
        "\n",
        "def create_data(n_samples):\n",
        "    # Lunas\n",
        "    moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
        "    # Blobs\n",
        "    blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
        "    # Datos desiguales\n",
        "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "    mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
        "\n",
        "    # Generamos Dataset\n",
        "    dataset = {\n",
        "        \"moons\": {\"x\": moons[0], \"classes\": moons[1], \"n_cluster\": 2},\n",
        "        \"blobs\": {\"x\": blobs[0], \"classes\": blobs[1], \"n_cluster\": 3},\n",
        "        \"mutated\": {\"x\": mutated[0], \"classes\": mutated[1], \"n_cluster\": 3},\n",
        "    }\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y51s6f_UtIkc"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cell_id": "643d6b35af5541358f481fda4d3fc51f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 267,
        "execution_start": 1714108733824,
        "id": "CO3JFqezrqC3",
        "outputId": "61a8cca1-3460-44dc-c23f-7dffb853b9a6",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "def plot_scatter(x, y, color, row, col, fig):\n",
        "    scatter = go.Scatter(\n",
        "        x=x,\n",
        "        y=y,\n",
        "        mode=\"markers\",\n",
        "        marker=dict(color=color, colorscale=\"Viridis\", line=dict(width=0.5)),\n",
        "        showlegend=False,\n",
        "    )\n",
        "    fig.add_trace(scatter, row=row, col=col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_all_clustering_results(datasets):\n",
        "    # Moons\n",
        "    x_moons = datasets[\"moons\"][\"x\"]\n",
        "    n_clusters_moons = datasets[\"moons\"][\"n_cluster\"]\n",
        "\n",
        "    # K-means\n",
        "    start_time_moons_kmeans = time.time()\n",
        "    kmeans_moons = KMeans(n_clusters=n_clusters_moons, random_state=10)\n",
        "    labels_moons_kmeans = kmeans_moons.fit_predict(x_moons)\n",
        "    exec_time_moons_kmeans = time.time() - start_time_moons_kmeans\n",
        "    silhouette_moons_kmeans = silhouette_score(x_moons, labels_moons_kmeans)\n",
        "\n",
        "    # GMM\n",
        "    start_time_moons_gmm = time.time()\n",
        "    gmm_moons = GaussianMixture(n_components=n_clusters_moons, random_state=10)\n",
        "    labels_moons_gmm = gmm_moons.fit(x_moons).predict(x_moons)\n",
        "    exec_time_moons_gmm = time.time() - start_time_moons_gmm\n",
        "    silhouette_moons_gmm = silhouette_score(x_moons, labels_moons_gmm)\n",
        "\n",
        "    # Ward\n",
        "    start_time_moons_ward = time.time()\n",
        "    ward_moons = AgglomerativeClustering(n_clusters=n_clusters_moons, linkage=\"ward\")\n",
        "    labels_moons_ward = ward_moons.fit_predict(x_moons)\n",
        "    exec_time_moons_ward = time.time() - start_time_moons_ward\n",
        "    silhouette_moons_ward = silhouette_score(x_moons, labels_moons_ward)\n",
        "\n",
        "    # DBSCAN\n",
        "    start_time_moons_dbscan = time.time()\n",
        "    dbscan_moons = DBSCAN(eps=0.5, min_samples=5)\n",
        "    labels_moons_dbscan = dbscan_moons.fit_predict(x_moons)\n",
        "    exec_time_moons_dbscan = time.time() - start_time_moons_dbscan\n",
        "    silhouette_moons_dbscan = (\n",
        "        silhouette_score(x_moons, labels_moons_dbscan)\n",
        "        if len(set(labels_moons_dbscan)) > 1\n",
        "        else -1\n",
        "    )\n",
        "\n",
        "    # Blobs\n",
        "    x_blobs = datasets[\"blobs\"][\"x\"]\n",
        "    n_clusters_blobs = datasets[\"blobs\"][\"n_cluster\"]\n",
        "\n",
        "    # K-means\n",
        "    start_time_blobs_kmeans = time.time()\n",
        "    kmeans_blobs = KMeans(n_clusters=n_clusters_blobs, random_state=10)\n",
        "    labels_blobs_kmeans = kmeans_blobs.fit_predict(x_blobs)\n",
        "    exec_time_blobs_kmeans = time.time() - start_time_blobs_kmeans\n",
        "    silhouette_blobs_kmeans = silhouette_score(x_blobs, labels_blobs_kmeans)\n",
        "\n",
        "    # GMM\n",
        "    start_time_blobs_gmm = time.time()\n",
        "    gmm_blobs = GaussianMixture(n_components=n_clusters_blobs, random_state=10)\n",
        "    labels_blobs_gmm = gmm_blobs.fit(x_blobs).predict(x_blobs)\n",
        "    exec_time_blobs_gmm = time.time() - start_time_blobs_gmm\n",
        "    silhouette_blobs_gmm = silhouette_score(x_blobs, labels_blobs_gmm)\n",
        "\n",
        "    # Ward\n",
        "    start_time_blobs_ward = time.time()\n",
        "    ward_blobs = AgglomerativeClustering(n_clusters=n_clusters_blobs, linkage=\"ward\")\n",
        "    labels_blobs_ward = ward_blobs.fit_predict(x_blobs)\n",
        "    exec_time_blobs_ward = time.time() - start_time_blobs_ward\n",
        "    silhouette_blobs_ward = silhouette_score(x_blobs, labels_blobs_ward)\n",
        "\n",
        "    # DBSCAN\n",
        "    start_time_blobs_dbscan = time.time()\n",
        "    dbscan_blobs = DBSCAN(eps=0.5, min_samples=5)\n",
        "    labels_blobs_dbscan = dbscan_blobs.fit_predict(x_blobs)\n",
        "    exec_time_blobs_dbscan = time.time() - start_time_blobs_dbscan\n",
        "    silhouette_blobs_dbscan = (\n",
        "        silhouette_score(x_blobs, labels_blobs_dbscan)\n",
        "        if len(set(labels_blobs_dbscan)) > 1\n",
        "        else -1\n",
        "    )\n",
        "\n",
        "    # Mutated\n",
        "    x_mutated = datasets[\"mutated\"][\"x\"]\n",
        "    n_clusters_mutated = datasets[\"mutated\"][\"n_cluster\"]\n",
        "\n",
        "    # K-means\n",
        "    start_time_mutated_kmeans = time.time()\n",
        "    kmeans_mutated = KMeans(n_clusters=n_clusters_mutated, random_state=10)\n",
        "    labels_mutated_kmeans = kmeans_mutated.fit_predict(x_mutated)\n",
        "    exec_time_mutated_kmeans = time.time() - start_time_mutated_kmeans\n",
        "    silhouette_mutated_kmeans = silhouette_score(x_mutated, labels_mutated_kmeans)\n",
        "\n",
        "    # GMM\n",
        "    start_time_mutated_gmm = time.time()\n",
        "    gmm_mutated = GaussianMixture(n_components=n_clusters_mutated, random_state=10)\n",
        "    labels_mutated_gmm = gmm_mutated.fit(x_mutated).predict(x_mutated)\n",
        "    exec_time_mutated_gmm = time.time() - start_time_mutated_gmm\n",
        "    silhouette_mutated_gmm = silhouette_score(x_mutated, labels_mutated_gmm)\n",
        "\n",
        "    # Ward\n",
        "    start_time_mutated_ward = time.time()\n",
        "    ward_mutated = AgglomerativeClustering(\n",
        "        n_clusters=n_clusters_mutated, linkage=\"ward\"\n",
        "    )\n",
        "    labels_mutated_ward = ward_mutated.fit_predict(x_mutated)\n",
        "    exec_time_mutated_ward = time.time() - start_time_mutated_ward\n",
        "    silhouette_mutated_ward = silhouette_score(x_mutated, labels_mutated_ward)\n",
        "\n",
        "    # DBSCAN\n",
        "    start_time_mutated_dbscan = time.time()\n",
        "    dbscan_mutated = DBSCAN(eps=0.5, min_samples=5)\n",
        "    labels_mutated_dbscan = dbscan_mutated.fit_predict(x_mutated)\n",
        "    exec_time_mutated_dbscan = time.time() - start_time_mutated_dbscan\n",
        "    silhouette_mutated_dbscan = (\n",
        "        silhouette_score(x_mutated, labels_mutated_dbscan)\n",
        "        if len(set(labels_mutated_dbscan)) > 1\n",
        "        else -1\n",
        "    )\n",
        "\n",
        "    fig = sp.make_subplots(\n",
        "        rows=3,\n",
        "        cols=4,\n",
        "        subplot_titles=[\n",
        "            f\"{exec_time_moons_kmeans:.2f}s, {silhouette_moons_kmeans:.2f}\",\n",
        "            f\"{exec_time_moons_gmm:.2f}s, {silhouette_moons_gmm:.2f}\",\n",
        "            f\"{exec_time_moons_ward:.2f}s,{silhouette_moons_ward:.2f}\",\n",
        "            f\"{exec_time_moons_dbscan:.2f}s, {silhouette_moons_dbscan:.2f}\",\n",
        "            f\"{exec_time_blobs_kmeans:.2f}s, {silhouette_blobs_kmeans:.2f}\",\n",
        "            f\"{exec_time_blobs_gmm:.2f}s, {silhouette_blobs_gmm:.2f}\",\n",
        "            f\"{exec_time_blobs_ward:.2f}s, {silhouette_blobs_ward:.2f}\",\n",
        "            f\"{exec_time_blobs_dbscan:.2f}s, {silhouette_blobs_dbscan:.2f}\",\n",
        "            f\"{exec_time_mutated_kmeans:.2f}s, {silhouette_mutated_kmeans:.2f}\",\n",
        "            f\"{exec_time_mutated_gmm:.2f}s, {silhouette_mutated_gmm:.2f}\",\n",
        "            f\"{exec_time_mutated_ward:.2f}s, {silhouette_mutated_ward:.2f}\",\n",
        "            f\"{exec_time_mutated_dbscan:.2f}s, {silhouette_mutated_dbscan:.2f}\",\n",
        "        ],\n",
        "        horizontal_spacing=0.05,\n",
        "        vertical_spacing=0.1,\n",
        "    )\n",
        "\n",
        "    plot_scatter(\n",
        "        x_moons[:, 0],\n",
        "        x_moons[:, 1],\n",
        "        labels_moons_kmeans,\n",
        "        1,\n",
        "        1,\n",
        "        fig,\n",
        "    )\n",
        "    plot_scatter(\n",
        "        x_moons[:, 0],\n",
        "        x_moons[:, 1],\n",
        "        labels_moons_gmm,\n",
        "        1,\n",
        "        2,\n",
        "        fig,\n",
        "    )\n",
        "    plot_scatter(\n",
        "        x_moons[:, 0],\n",
        "        x_moons[:, 1],\n",
        "        labels_moons_ward,\n",
        "        1,\n",
        "        3,\n",
        "        fig,\n",
        "    )\n",
        "    plot_scatter(\n",
        "        x_moons[:, 0],\n",
        "        x_moons[:, 1],\n",
        "        labels_moons_dbscan,\n",
        "        1,\n",
        "        4,\n",
        "        fig,\n",
        "    )\n",
        "\n",
        "    # Blobs\n",
        "    plot_scatter(\n",
        "        x_blobs[:, 0],\n",
        "        x_blobs[:, 1],\n",
        "        labels_blobs_kmeans,\n",
        "        2,\n",
        "        1,\n",
        "        fig,\n",
        "    )\n",
        "    plot_scatter(\n",
        "        x_blobs[:, 0],\n",
        "        x_blobs[:, 1],\n",
        "        labels_blobs_gmm,\n",
        "        2,\n",
        "        2,\n",
        "        fig,\n",
        "    )\n",
        "    plot_scatter(\n",
        "        x_blobs[:, 0],\n",
        "        x_blobs[:, 1],\n",
        "        labels_blobs_ward,\n",
        "        2,\n",
        "        3,\n",
        "        fig,\n",
        "    )\n",
        "    plot_scatter(\n",
        "        x_blobs[:, 0],\n",
        "        x_blobs[:, 1],\n",
        "        labels_blobs_dbscan,\n",
        "        2,\n",
        "        4,\n",
        "        fig,\n",
        "    )\n",
        "\n",
        "    # Mutated\n",
        "    plot_scatter(\n",
        "        x_mutated[:, 0],\n",
        "        x_mutated[:, 1],\n",
        "        labels_mutated_kmeans,\n",
        "        3,\n",
        "        1,\n",
        "        fig,\n",
        "    )\n",
        "    plot_scatter(\n",
        "        x_mutated[:, 0],\n",
        "        x_mutated[:, 1],\n",
        "        labels_mutated_gmm,\n",
        "        3,\n",
        "        2,\n",
        "        fig,\n",
        "    )\n",
        "    plot_scatter(\n",
        "        x_mutated[:, 0],\n",
        "        x_mutated[:, 1],\n",
        "        labels_mutated_ward,\n",
        "        3,\n",
        "        3,\n",
        "        fig,\n",
        "    )\n",
        "    plot_scatter(\n",
        "        x_mutated[:, 0],\n",
        "        x_mutated[:, 1],\n",
        "        labels_mutated_dbscan,\n",
        "        3,\n",
        "        4,\n",
        "        fig,\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        height=600,\n",
        "        width=800,\n",
        "        title_x=0.5,\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_samples = 1000\n",
        "data = create_data(n_samples)\n",
        "plot_all_clustering_results(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear los datos y graficar los resultados\n",
        "n_samples = 5000\n",
        "data = create_data(n_samples)\n",
        "plot_all_clustering_results(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear los datos y graficar los resultados\n",
        "n_samples = 10000\n",
        "data = create_data(n_samples)\n",
        "plot_all_clustering_results(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. \n",
        "\n",
        "Para todos los casos el primer gr√°fico de DBScan tiene malos resultados, dado que no distingue. \n",
        "En cuanto a resultados seg√∫n los gr√°ficos y la m√©trica de Silhoutte, DBSCAN tiene los peores resultados. \n",
        "Por lo general, WARD es el que toma m√°s tiempo de ejecuci√≥n respecto a los otros algoritmos. \n",
        "En cuanto a la valoraci√≥n de resultados en funci√≥n de los tiempos de ejecuci√≥n, GMM es el mejor algoritmo, para estos datos y esta configuraci√≥n de par√°metros.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "13c5cb8067d9415f83b3d497954a437a",
        "deepnote_cell_type": "markdown",
        "id": "3mCbZc86rqC6"
      },
      "source": [
        "## 2. An√°lisis de Satisfacci√≥n de Vuelos. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd6e991646b44f50a4b13f01d1542415",
        "deepnote_cell_type": "markdown",
        "id": "JI33m5jbrqC6"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/2Hci.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5742dfbd5a2e43778ff250436bab1005",
        "deepnote_cell_type": "markdown",
        "id": "h5k24znirqC7"
      },
      "source": [
        "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_licer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
        "\n",
        "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
        "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
        "- *Age*: Edad actual de los pasajeros\n",
        "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
        "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
        "- *Flight distance*: Distancia del vuelo de este viaje\n",
        "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
        "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
        "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
        "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
        "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
        "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
        "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
        "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
        "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
        "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
        "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
        "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
        "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
        "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
        "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
        "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOoIFHpw5xCW"
      },
      "source": [
        "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
        "\n",
        "0. Ingeste el dataset a su ambiente de trabajo.\n",
        "\n",
        "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
        "\n",
        "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
        "\n",
        "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
        "\n",
        "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
        "\n",
        "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6tcVBCtxxS"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzHTZ17xveU_"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(\"aerolineas_lucer.parquet\")\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "var_num = df.select_dtypes(include=[\"number\"])\n",
        "var_num = var_num.drop(columns=[\"id\"])\n",
        "var_num.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En un algoritmo no supervisado las variables categ√≥ricas pueden tener efectos negativos porque, generalmente, los algoritmos usan medidas de distancia para establecer a que cluster pertenece cada dato. En ese caso, con variables que no pueden cumplir esta condici√≥n no se pueden calcular de buena manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig1 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[0],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[0]}\",\n",
        ")\n",
        "fig1.show()\n",
        "\n",
        "fig2 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[1],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[1]}\",\n",
        ")\n",
        "fig2.show()\n",
        "\n",
        "fig3 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[2],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[2]}\",\n",
        ")\n",
        "fig3.show()\n",
        "\n",
        "fig4 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[3],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[3]}\",\n",
        ")\n",
        "fig4.show()\n",
        "\n",
        "fig5 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[4],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[4]}\",\n",
        ")\n",
        "fig5.show()\n",
        "\n",
        "fig6 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[5],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[5]}\",\n",
        ")\n",
        "fig6.show()\n",
        "\n",
        "fig7 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[6],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[6]}\",\n",
        ")\n",
        "fig7.show()\n",
        "\n",
        "fig8 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[7],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[7]}\",\n",
        ")\n",
        "fig8.show()\n",
        "\n",
        "fig9 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[8],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[8]}\",\n",
        ")\n",
        "fig9.show()\n",
        "\n",
        "fig10 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[9],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[9]}\",\n",
        ")\n",
        "fig10.show()\n",
        "\n",
        "fig11 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[10],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[10]}\",\n",
        ")\n",
        "fig11.show()\n",
        "\n",
        "fig12 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[11],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[11]}\",\n",
        ")\n",
        "fig12.show()\n",
        "\n",
        "fig13 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[12],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[12]}\",\n",
        ")\n",
        "fig13.show()\n",
        "\n",
        "fig14 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[13],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[13]}\",\n",
        ")\n",
        "fig14.show()\n",
        "\n",
        "fig15 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[14],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[14]}\",\n",
        ")\n",
        "fig15.show()\n",
        "\n",
        "fig16 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[15],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[15]}\",\n",
        ")\n",
        "fig16.show()\n",
        "\n",
        "fig17 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[16],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[16]}\",\n",
        ")\n",
        "fig17.show()\n",
        "\n",
        "fig18 = px.histogram(\n",
        "    var_num,\n",
        "    x=var_num.columns[17],\n",
        "    nbins=30,\n",
        "    title=f\"Distribuci√≥n de {var_num.columns[17]}\",\n",
        ")\n",
        "fig18.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En particular hay 2 variables que tienen valores distintos al resto, las variables de delay in minutes no tienen valores categoricos de a 1 a 5 por lo que su representaci√≥n y valoraci√≥n en un modelo es distinto. Visto de esta forma, es necesario escalar los datos. Viendo las variables: La edad cumple casi con una distribuci√≥n normal alrededor de los 40 a√±os, el flight distance se concentra en menos de 10.000, casi todas las variables categ√≥ricas se concentran entre 3, 4 o 5, y los delay son menores de 200 casi todos. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaled_array = scaler.fit_transform(var_num)\n",
        "\n",
        "df_scaled = pd.DataFrame(scaled_array, columns=var_num.columns, index=var_num.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "matriz_correlacion = df_scaled.corr()\n",
        "\n",
        "fig = ff.create_annotated_heatmap(\n",
        "    z=matriz_correlacion.values,\n",
        "    x=list(matriz_correlacion.columns),\n",
        "    y=list(matriz_correlacion.columns),\n",
        "    annotation_text=np.round(matriz_correlacion.values, 2),\n",
        "    colorscale=\"Viridis\",\n",
        ")\n",
        "fig.update_layout(title=\"Correlograma\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. De acuerdo con los resultados obtenidos en 4), reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]\n",
        "\n",
        "En vista de que hay variables que est√°n muy correlacionadas, se seleccionan las siguientes:\n",
        "- Age, porque segmenta bien a los clientes y tiene poca correlaci√≥n con el resto de variables \n",
        "- Departure Delay in Minutes, porque con la otra variable de delay son identicas y son muy distintas al resto \n",
        "- Checkin service, porque tiene baja correlaci√≥n con las dem√°s variables y puede tener m√°s impacto que otras variables poca correlacionadas (era esta o Flight Distance)\n",
        "- Inflight entertainment, porque est√° muy correlacionada con hartas variables, pero poco correlacionada con las otras 3 variables elegidas, as√≠ que representa bien a las no elegidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_importante = df_scaled[\n",
        "    [\"Age\", \"Departure Delay in Minutes\", \"Checkin service\", \"Inflight entertainment\"]\n",
        "]\n",
        "df_importante.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4b6c047d994f40ea9e78a36a777042e0",
        "deepnote_cell_type": "markdown",
        "id": "PNGfTgtkrqC9"
      },
      "source": [
        "## 3. Preprocesamiento üé≠. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "713b3f0e61dd4841bb5b38c730d344d5",
        "deepnote_cell_type": "markdown",
        "id": "6RZD0fMNrqC-"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/1e/a8/0e/1ea80e7cea0d429146580c7e91c5b944.gif\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "98400c7b5fec4af193eec3601f53891e",
        "deepnote_cell_type": "markdown",
        "id": "J6d4VEOTrqC-"
      },
      "source": [
        "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
        "\n",
        "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
        "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
        "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDSaGoq0OUp"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cell_id": "ad1e70818ad748638ca0927b07a76125",
        "deepnote_cell_type": "code",
        "id": "gBYG238wrqC-"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=2))])\n",
        "\n",
        "pca_result = pipeline.fit_transform(df_importante)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_df = pd.DataFrame(pca_result, columns=[\"PCA1\", \"PCA2\"])\n",
        "\n",
        "fig = px.scatter(\n",
        "    pca_df,\n",
        "    x=\"PCA1\",\n",
        "    y=\"PCA2\",\n",
        "    title=\"Proyecci√≥n PCA a 2 Dimensiones\",\n",
        "    labels={\"PCA1\": \"Componente Principal 1\", \"PCA2\": \"Componente Principal 2\"},\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bd281470d3054764a63d857cfa7d52a6",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "7ENoOtIIrqC_"
      },
      "source": [
        "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "db89e9c9f35c44abbd8991180226c0ea",
        "deepnote_cell_type": "markdown",
        "id": "fbGw6Sa-rqC_"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://joachim-gassen.github.io/images/ani_sim_bad_leverage.gif\" width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3e2f59fa12954641af7a854a4e203694",
        "deepnote_cell_type": "markdown",
        "id": "nl_ccu9brqDA"
      },
      "source": [
        "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
        "\n",
        "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset (sin aplicar PCA), configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
        "\n",
        "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
        "\n",
        "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cS1FR00NlF"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cell_id": "be86896911244aa89e3b5f3f00a286af",
        "deepnote_cell_type": "code",
        "id": "iaPZFmjyrqDA"
      },
      "outputs": [],
      "source": [
        "important_data_array = df_importante.to_numpy()\n",
        "\n",
        "pipeline_anomaly = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"isolation_forest\", IsolationForest(contamination=0.01, random_state=10)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipeline_anomaly.fit(important_data_array)\n",
        "\n",
        "anomalia_casos = pipeline_anomaly.named_steps[\"isolation_forest\"].predict(\n",
        "    important_data_array\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_df[\"anomaly\"] = anomalia_casos\n",
        "\n",
        "fig = px.scatter(\n",
        "    pca_df,\n",
        "    x=\"PCA1\",\n",
        "    y=\"PCA2\",\n",
        "    color=\"anomaly\",\n",
        "    color_discrete_map={1: \"blue\", -1: \"red\"},\n",
        "    title=\"Proyecci√≥n PCA con Detecci√≥n de Anomal√≠as (IsolationForest)\",\n",
        "    labels={\n",
        "        \"PCA1\": \"Componente Principal 1\",\n",
        "        \"PCA2\": \"Componente Principal 2\",\n",
        "        \"anomaly\": \"Anomal√≠a\",\n",
        "    },\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sin saber si apliqu√© todo bien, lo calificar√≠a mal, ya que gr√°ficamente no est√° mostrando como anomal√≠as a los datos m√°s distantes, cuando si deber√≠a ser el caso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3871e2fe5bdd422dbdbfaebf75503ae3",
        "deepnote_cell_type": "markdown",
        "id": "zQFTklmVrqDB"
      },
      "source": [
        "## 5. M√©tricas de Desempe√±o üöÄ [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "236333de6dd445c182aefcc507589325",
        "deepnote_cell_type": "markdown",
        "id": "YpNj4wbPrqDB"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a7e1ceb91be94b1da2ab8be97dfac999",
        "deepnote_cell_type": "markdown",
        "id": "CR3hzRxrrqDB"
      },
      "source": [
        "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
        "\n",
        "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
        "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
        "\n",
        "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_T_zTg0MXB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cell_id": "6d3d1bb3fda14321984466d9101a775a",
        "deepnote_cell_type": "code",
        "id": "5GeUb9J3rqDB"
      },
      "outputs": [],
      "source": [
        "pipeline_gmm = Pipeline(\n",
        "    [(\"scaler\", StandardScaler()), (\"gmm\", GaussianMixture(random_state=10))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "important_data_array = df_importante.to_numpy()\n",
        "\n",
        "# n_clusters=3\n",
        "pipeline_gmm_3 = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"gmm\", GaussianMixture(n_components=3, random_state=10)),\n",
        "    ]\n",
        ")\n",
        "pipeline_gmm_3.fit(important_data_array)\n",
        "gmm_3 = pipeline_gmm_3.named_steps[\"gmm\"]\n",
        "aic_3 = gmm_3.aic(important_data_array)\n",
        "bic_3 = gmm_3.bic(important_data_array)\n",
        "\n",
        "# n_clusters=4\n",
        "pipeline_gmm_4 = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"gmm\", GaussianMixture(n_components=4, random_state=10)),\n",
        "    ]\n",
        ")\n",
        "pipeline_gmm_4.fit(important_data_array)\n",
        "gmm_4 = pipeline_gmm_4.named_steps[\"gmm\"]\n",
        "aic_4 = gmm_4.aic(important_data_array)\n",
        "bic_4 = gmm_4.bic(important_data_array)\n",
        "\n",
        "# n_clusters=5\n",
        "pipeline_gmm_5 = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"gmm\", GaussianMixture(n_components=5, random_state=10)),\n",
        "    ]\n",
        ")\n",
        "pipeline_gmm_5.fit(important_data_array)\n",
        "gmm_5 = pipeline_gmm_5.named_steps[\"gmm\"]\n",
        "aic_5 = gmm_5.aic(important_data_array)\n",
        "bic_5 = gmm_5.bic(important_data_array)\n",
        "\n",
        "# n_clusters=6\n",
        "pipeline_gmm_6 = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"gmm\", GaussianMixture(n_components=6, random_state=10)),\n",
        "    ]\n",
        ")\n",
        "pipeline_gmm_6.fit(important_data_array)\n",
        "gmm_6 = pipeline_gmm_6.named_steps[\"gmm\"]\n",
        "aic_6 = gmm_6.aic(important_data_array)\n",
        "bic_6 = gmm_6.bic(important_data_array)\n",
        "\n",
        "# n_clusters=7\n",
        "pipeline_gmm_7 = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"gmm\", GaussianMixture(n_components=7, random_state=10)),\n",
        "    ]\n",
        ")\n",
        "pipeline_gmm_7.fit(important_data_array)\n",
        "gmm_7 = pipeline_gmm_7.named_steps[\"gmm\"]\n",
        "aic_7 = gmm_7.aic(important_data_array)\n",
        "bic_7 = gmm_7.bic(important_data_array)\n",
        "\n",
        "# n_clusters=8\n",
        "pipeline_gmm_8 = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"gmm\", GaussianMixture(n_components=8, random_state=10)),\n",
        "    ]\n",
        ")\n",
        "pipeline_gmm_8.fit(important_data_array)\n",
        "gmm_8 = pipeline_gmm_8.named_steps[\"gmm\"]\n",
        "aic_8 = gmm_8.aic(important_data_array)\n",
        "bic_8 = gmm_8.bic(important_data_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_clusters = [3, 4, 5, 6, 7, 8]\n",
        "aic_scores = [aic_3, aic_4, aic_5, aic_6, aic_7, aic_8]\n",
        "bic_scores = [bic_3, bic_4, bic_5, bic_6, bic_7, bic_8]\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=n_clusters,\n",
        "        y=aic_scores,\n",
        "        mode=\"lines+markers\",\n",
        "        name=\"AIC\",\n",
        "        line=dict(color=\"blue\"),\n",
        "        marker=dict(size=10),\n",
        "    )\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=n_clusters,\n",
        "        y=bic_scores,\n",
        "        mode=\"lines+markers\",\n",
        "        name=\"BIC\",\n",
        "        line=dict(color=\"red\"),\n",
        "        marker=dict(size=10),\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"AIC y BIC \",\n",
        "    xaxis_title=\"N√∫mero de Clusters\",\n",
        "    yaxis_title=\"AIC / BIC\",\n",
        "    legend_title=\"Criterios\",\n",
        "    height=500,\n",
        "    width=800,\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "dd342e336254418ba766b29dce16b267",
        "deepnote_cell_type": "markdown",
        "id": "P9CERnaerqDC"
      },
      "source": [
        "## 6. An√°lisis de resultados üìä [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "953b5ad01a704b50b899db7176d1b7b2",
        "deepnote_cell_type": "markdown",
        "id": "I1yNa111rqDC"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/7wTk.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd90e2f135404353ac0b5ab844936ca7",
        "deepnote_cell_type": "markdown",
        "id": "dg0Qx4RZrqDC"
      },
      "source": [
        "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
        "\n",
        "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
        "\n",
        "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "\n",
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
        "\n",
        "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
        "\n",
        "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRN0zZip0IMB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "9abf4dbc643e40cebe99fcb1ff3ff413",
        "deepnote_cell_type": "code",
        "id": "XmZrz15GrqDC"
      },
      "outputs": [],
      "source": [
        "pipeline_gmm_7.fit(df_importante)\n",
        "gmm_7 = pipeline_gmm_7.named_steps[\"gmm\"]\n",
        "cluster_labels = gmm_7.predict(df_importante)\n",
        "\n",
        "pca_result = pipeline.named_steps[\"pca\"].transform(df_importante)\n",
        "\n",
        "pca_df = pd.DataFrame(pca_result, columns=[\"PCA1\", \"PCA2\"])\n",
        "pca_df[\"cluster\"] = cluster_labels\n",
        "\n",
        "fig = px.scatter(\n",
        "    pca_df,\n",
        "    x=\"PCA1\",\n",
        "    y=\"PCA2\",\n",
        "    color=\"cluster\",\n",
        "    title=\"Visualizaci√≥n de Cl√∫sters en 2D\",\n",
        "    labels={\n",
        "        \"PCA1\": \"Componente Principal 1\",\n",
        "        \"PCA2\": \"Componente Principal 2\",\n",
        "        \"cluster\": \"Cluster\",\n",
        "    },\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. \n",
        "Es posible distinguir clusters, pero no de forma clara, ya que hay muchos datos concentrados en un cluster y este se podr√≠a segmentar un m√°s. De todos modos, no hay datos mezclados dentro de los clusters y eso es bueno."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_importante[\"cluster\"] = cluster_labels\n",
        "\n",
        "cluster_stats = df_importante.groupby(\"cluster\").agg([\"mean\", \"std\"])\n",
        "cluster_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. \n",
        "\n",
        "Viendo las medias y desviaciones estandar, los clusters se pueden diferenciar, particularmente viendo las medias. Ya las desviaci√≥n estandar indican que hay variables que no est√°n tan concentradas en la media, como el caso de Departure Delay in Minutes. Por lo demas, en las otras variables si se puede considerar que hay diferencias entre ambos casos. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_3d = PCA(n_components=3)\n",
        "pca_result_3d = pca_3d.fit_transform(\n",
        "    StandardScaler().fit_transform(df_importante.drop(columns=\"cluster\"))\n",
        ")\n",
        "\n",
        "pca_3d_df = pd.DataFrame(pca_result_3d, columns=[\"PCA1\", \"PCA2\", \"PCA3\"])\n",
        "pca_3d_df[\"cluster\"] = cluster_labels\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    pca_3d_df,\n",
        "    x=\"PCA1\",\n",
        "    y=\"PCA2\",\n",
        "    z=\"PCA3\",\n",
        "    color=\"cluster\",\n",
        "    title=\"Visualizaci√≥n de Cl√∫sters en 3D\",\n",
        "    labels={\n",
        "        \"PCA1\": \"Componente Principal 1\",\n",
        "        \"PCA2\": \"Componente Principal 2\",\n",
        "        \"PCA3\": \"Componente Principal 3\",\n",
        "        \"cluster\": \"Cluster\",\n",
        "    },\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. \n",
        "En una visualizaci√≥n de 3 dimensiones de los cl√∫sters, se puede observar que los clusters est√°n mejor separados, al menos es m√°s clara la diferencia. \n",
        "Esto da a entender que el modelo de Gaussian Mixture ha sido capaz de identificar patrones en los datos que permiten agruparlos de manera efectiva."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
    "deepnote_persisted_session": {
      "createdAt": "2024-04-26T06:15:51.197Z"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
